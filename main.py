# -*- coding: utf-8 -*-
import feedparser
import requests
import hashlib
import os
import re
import subprocess

from wand.image import Image
from wand.drawing import Drawing
from wand.color import Color

import arabic_reshaper
from bidi.algorithm import get_display

# =========================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª RSS + Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
# =========================
FEEDS = [
    {
        "name": "Ø§Ø®Ø¨Ø§Ø± Ù‚Ù†Ø§",
        "url": "https://qenanews-24.blogspot.com/feeds/posts/default/-/Ø§Ø®Ø¨Ø§Ø±%20Ù‚Ù†Ø§?alt=rss",
        "overlay": "qena.png",
        "text_color": "white",
    },
    {
        "name": "Ø­ÙˆØ§Ø¯Ø«",
        "url": "https://qenanews-24.blogspot.com/feeds/posts/default/-/Ø­ÙˆØ§Ø¯Ø«?alt=rss",
        "overlay": "news.png",
        "text_color": "white",
    },
    {
        "name": "Ø¨Ø±Ù„Ù…Ø§Ù† 25",
        "url": "https://qenanews-24.blogspot.com/feeds/posts/default/-/Ø¨Ø±Ù„Ù…Ø§Ù†%2025?alt=rss",
        "overlay": "barlman.png",
        "text_color": "white",
    },
    {
        "name": "Ø±ÙŠØ§Ø¶Ø©",
        "url": "https://qenanews-24.blogspot.com/feeds/posts/default/-/Ø±ÙŠØ§Ø¶Ø©?alt=rss",
        "overlay": "sport.png",
        "text_color": "black",
    },
    {
        "name": "Ø¹Ù„ÙˆÙ… ÙˆØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§",
        "url": "https://qenanews-24.blogspot.com/feeds/posts/default/-/Ø¹Ù„ÙˆÙ…%20ÙˆØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§?alt=rss",
        "overlay": "tecno.png",
        "text_color": "black",
    },
    {
        "name": "ØµØ­Ø© ÙˆÙÙ†",
        "url": "https://qenanews-24.blogspot.com/feeds/posts/default/-/ØµØ­Ø©%20ÙˆÙÙ†?alt=rss",
        "overlay": "art.png",
        "text_color": "black",
    },
]

FONT_FILE = "29ltbukrabolditalic.otf"
POSTED_FILE = "posted_articles.txt"
INDEX_FILE = "last_feed_index.txt"

PAGE_ID = os.getenv("PAGE_ID")
PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN")
FB_URL = f"https://graph.facebook.com/v19.0/{PAGE_ID}/photos"

# ============================
# Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù†Øµ
# ============================
TEXT_LEFT = 55
TEXT_RIGHT = 1030
TEXT_TOP = 765
TEXT_BOTTOM = 980

CENTER_X = (TEXT_LEFT + TEXT_RIGHT) // 2
MAX_WIDTH = TEXT_RIGHT - TEXT_LEFT
MAX_HEIGHT = TEXT_BOTTOM - TEXT_TOP

# ============================
# Ø§Ù„Ø£Ù…Ø§ÙƒÙ† ÙˆØ§Ù„Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª
# ============================
PLACES = [
    "Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©","Ø§Ù„Ø¬ÙŠØ²Ø©","Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©","Ø§Ù„Ø¯Ù‚Ù‡Ù„ÙŠØ©","Ø§Ù„Ø´Ø±Ù‚ÙŠØ©","Ø§Ù„Ù‚Ù„ÙŠÙˆØ¨ÙŠØ©",
    "ÙƒÙØ± Ø§Ù„Ø´ÙŠØ®","Ø§Ù„ØºØ±Ø¨ÙŠØ©","Ø§Ù„Ù…Ù†ÙˆÙÙŠØ©","Ø§Ù„Ø¨Ø­ÙŠØ±Ø©","Ø¯Ù…ÙŠØ§Ø·",
    "Ø¨ÙˆØ±Ø³Ø¹ÙŠØ¯","Ø§Ù„Ø¥Ø³Ù…Ø§Ø¹ÙŠÙ„ÙŠØ©","Ø§Ù„Ø³ÙˆÙŠØ³",
    "Ø§Ù„ÙÙŠÙˆÙ…","Ø¨Ù†ÙŠ Ø³ÙˆÙŠÙ","Ø§Ù„Ù…Ù†ÙŠØ§","Ø£Ø³ÙŠÙˆØ·","Ø³ÙˆÙ‡Ø§Ø¬","Ù‚Ù†Ø§","Ø§Ù„Ø£Ù‚ØµØ±","Ø£Ø³ÙˆØ§Ù†",
    "Ø§Ù„Ø¨Ø­Ø± Ø§Ù„Ø£Ø­Ù…Ø±","Ø§Ù„ÙˆØ§Ø¯ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯","Ù…Ø·Ø±ÙˆØ­","Ø´Ù…Ø§Ù„ Ø³ÙŠÙ†Ø§Ø¡","Ø¬Ù†ÙˆØ¨ Ø³ÙŠÙ†Ø§Ø¡",
    "Ù…Ø¯ÙŠÙ†Ø© Ù‚Ù†Ø§","Ù…Ø±ÙƒØ² Ù‚Ù†Ø§","Ù†Ø¬Ø¹ Ø­Ù…Ø§Ø¯ÙŠ","Ù…Ø±ÙƒØ² Ù†Ø¬Ø¹ Ø­Ù…Ø§Ø¯ÙŠ",
    "Ø¯Ø´Ù†Ø§","Ù…Ø±ÙƒØ² Ø¯Ø´Ù†Ø§","Ù‚ÙØ·","Ù…Ø±ÙƒØ² Ù‚ÙØ·","Ù‚ÙˆØµ","Ù…Ø±ÙƒØ² Ù‚ÙˆØµ",
    "Ø£Ø¨Ùˆ ØªØ´Øª","Ù…Ø±ÙƒØ² Ø£Ø¨Ùˆ ØªØ´Øª","ÙØ±Ø´ÙˆØ·","Ù…Ø±ÙƒØ² ÙØ±Ø´ÙˆØ·",
    "Ù†Ù‚Ø§Ø¯Ø©","Ù…Ø±ÙƒØ² Ù†Ù‚Ø§Ø¯Ø©","Ø§Ù„ÙˆÙ‚Ù","Ù…Ø±ÙƒØ² Ø§Ù„ÙˆÙ‚Ù"
]

GOV_ENTITIES = ["Ø§Ù„Ù†ÙŠØ§Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø©","ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©","ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¹Ø¯Ù„","Ù…Ø­ÙƒÙ…Ø©","Ø§Ù„Ø´Ø±Ø·Ø©","Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø£Ù…Ù†ÙŠØ©"]

SECTIONS = {
    "Ù‚Ø¶Ø§Ø¦ÙŠ": ["Ù…Ø­ÙƒÙ…Ø©","Ø§Ù„Ù†ÙŠØ§Ø¨Ø©","Ø­ÙƒÙ…","Ù‚Ø¶Øª"],
    "Ø£Ù…Ù†ÙŠ": ["Ø§Ù„Ù‚Ø¨Ø¶","Ø§Ù„Ø£Ù…Ù†","Ø§Ù„Ø´Ø±Ø·Ø©","ØªÙØªÙŠØ´"],
    "ØªØ¹Ù„ÙŠÙ…ÙŠ": ["Ù…Ø¯Ø±Ø³","Ø·Ù„Ø§Ø¨","ØªØ¹Ù„ÙŠÙ…","Ù…Ø¯Ø±Ø³Ø©"],
    "Ø±ÙŠØ§Ø¶ÙŠ": ["Ù…Ø¨Ø§Ø±Ø§Ø©","Ù„Ø§Ø¹Ø¨","Ù†Ø§Ø¯ÙŠ","Ø¨Ø·ÙˆÙ„Ø©"]
}

# ============================
# Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø©
# ============================
def shape_text(txt):
    return get_display(arabic_reshaper.reshape(txt))

def detect_section(text):
    for sec, keys in SECTIONS.items():
        for k in keys:
            if k in text:
                return sec
    return "Ø£Ø®Ø¨Ø§Ø±"

def normalize_hashtag(text):
    return text.replace(" ", "_")

def extract_safe_hashtags(text):
    tags = ["Ù‚Ù†Ø§_Ù†ÙŠÙˆØ²_24"]
    for p in PLACES:
        if p in text:
            tags.append(normalize_hashtag(p))
            break
    for g in GOV_ENTITIES:
        if g in text:
            tags.append(normalize_hashtag(g))
            break
    tags.append(normalize_hashtag(detect_section(text)))
    return " ".join(f"#{t}" for t in tags)

# =========================
# Ø§Ù„ØªÙ†ÙÙŠØ°
# =========================
def main():
    feed_index = 0
    if os.path.exists(INDEX_FILE):
        feed_index = int(open(INDEX_FILE).read().strip())

    feed_cfg = FEEDS[feed_index % len(FEEDS)]
    open(INDEX_FILE, "w").write(str(feed_index + 1))

    feed = feedparser.parse(feed_cfg["url"])

    posted = []
    if os.path.exists(POSTED_FILE):
        posted = open(POSTED_FILE, encoding="utf-8").read().splitlines()

    for entry in feed.entries:
        title = re.sub("<.*?>", "", entry.title).strip()
        h = hashlib.md5(title.encode()).hexdigest()
        if h in posted:
            continue

        m = re.search(r'<img[^>]+src="([^">]+)"', entry.summary)
        if not m:
            continue

        r = requests.get(m.group(1), timeout=15)

        with Image(width=1080, height=1080, background=Color("white")) as canvas:
            canvas.alpha_channel = 'activate'

            # ØµÙˆØ±Ø© Ø§Ù„Ø®Ø¨Ø±
            with Image(blob=r.content) as news:
                news.format = "png"
                news.alpha_channel = 'activate'
                news.resize(1080, 715)
                canvas.composite(news, 0, 0)

            # Overlay Ø§Ù„Ù‚Ø³Ù…
            with Image(filename=feed_cfg["overlay"]) as overlay:
                overlay.alpha_channel = 'activate'
                overlay.resize(1080, 1080)
                canvas.composite(overlay, 0, 0)

            # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
            with Drawing() as draw:
                draw.font = FONT_FILE
                draw.font_size = 52
                draw.fill_color = Color(feed_cfg["text_color"])
                draw.text_alignment = "center"

                shaped = shape_text(title)
                draw.text(CENTER_X, TEXT_TOP + 40, shaped)
                draw(canvas)

            canvas.format = "png"
            canvas.alpha_channel = 'remove'
            canvas.save(filename="final.png")

        # ---------- ÙƒØ§Ø¨Ø´Ù† ÙÙŠØ³Ø¨ÙˆÙƒ (Ø£ÙˆÙ„ 50 ÙƒÙ„Ù…Ø© + ØªØ§Ø¨Ø¹ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø®Ø¨Ø± + Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª) ----------
        clean_summary = re.sub("<.*?>", "", entry.summary)
        first_50 = " ".join(clean_summary.split()[:50])
        caption = (
            f"{title}

"
            f"{first_50}...
"
            f"ØªØ§Ø¨Ø¹ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø®Ø¨Ø± Ù…Ù† Ù‡Ù†Ø§ ğŸ‘‡
"
            f"{entry.link}

"
            f"{extract_safe_hashtags(title)}"
        )

        with open("final.png", "rb") as img:
            res = requests.post(
                FB_URL,
                data={"access_token": PAGE_ACCESS_TOKEN, "caption": caption},
                files={"source": img},
            )

        if res.status_code == 200:
            open(POSTED_FILE, "a", encoding="utf-8").write(h + "\n")
            print("âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø±")
            break
        else:
            print("âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±", res.text)

if __name__ == "__main__":
    main()
