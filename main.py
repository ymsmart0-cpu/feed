# -*- coding: utf-8 -*-
import feedparser
import requests
import hashlib
import os
import re
import random
import subprocess

from wand.image import Image
from wand.drawing import Drawing
from wand.color import Color

import arabic_reshaper
from bidi.algorithm import get_display

# ============================
# ุงูุฅุนุฏุงุฏุงุช ุงูุนุงูุฉ
# ============================
RSS_URL = "https://qenanews-24.blogspot.com/feeds/posts/default?alt=rss"
FONT_FILE = "29ltbukrabolditalic.otf"

BG_IMAGE = "BG.png"
LOGO_IMAGE = "logo1.png"

# ุญุฏูุฏ ุงููุต
TEXT_LEFT = 110
TEXT_RIGHT = 960
TEXT_TOP = 725
TEXT_BOTTOM = 880

MAX_WIDTH = TEXT_RIGHT - TEXT_LEFT
MAX_HEIGHT = TEXT_BOTTOM - TEXT_TOP

CENTER_X = TEXT_LEFT + MAX_WIDTH // 2
LINE_HEIGHT = 70

POSTED_FILE = "posted_articles.txt"

PAGE_ID = os.getenv("PAGE_ID", "").strip()
PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN", "").strip()
FB_URL = f"https://graph.facebook.com/v19.0/{PAGE_ID}/photos"

# ============================
# ูููุงุช ุญุณุงุณุฉ
# ============================
SEPARATORS = ["$", "โข", "~", "+", "|", "=", "^", "!", "ยท", "โ"]

def break_word_inside(word):
    """
    ููุณุฑ ุฃู ูููุฉ ุญุณุงุณุฉ ุญุชู ูู ูุงูุช ููุชุตูุฉ ุจุญุฑูู ูุจููุง ุฃู ุจุนุฏูุง
    ูุซุงู: ุจุงูุชุญุฑุด โ ุจุงูุชุญุฑโขุด
    """
    for sensitive in SENSITIVE_WORDS:
        if sensitive in word:
            symbol = random.choice(SEPARATORS)
            pos = len(sensitive) // 2
            broken = sensitive[:pos] + symbol + sensitive[pos:]
            return word.replace(sensitive, broken, 1)
    return word

def process_sensitive_text(text, limit_once=False):
    words = text.split()
    used = False
    result = []

    for w in words:
        has_sensitive = any(s in w for s in SENSITIVE_WORDS)

        if has_sensitive and (not used or not limit_once):
            result.append(break_word_inside(w))
            used = True
        else:
            result.append(w)

    return " ".join(result)

SENSITIVE_WORDS = [

    # ===== ุฌุฑุงุฆู ูุนูู =====
    "ูุชู","ููุชู","ูุชูู","ููุชู","ูุชูุชู",
    "ุฌุฑููุฉ","ุฌุฑุงุฆู","ูุฌุฑู",
    "ุฐุจุญ","ูุฐุจูุญ",
    "ุทุนู","ูุทุนูู",
    "ุถุฑุจ","ุงุนุชุฏุงุก","ุงุนุชุฏุงุกุงุช",
    "ุนูู","ุชุนุฐูุจ",
    "ุฏู","ุฏูุงุก","ูุฒูู",
    "ุณูุงุญ","ุฃุณูุญุฉ","ุณูุงุญ ุฃุจูุถ","ุณููู","ูุทูุงุฉ",
    "ุฅุทูุงู ูุงุฑ","ุฑุตุงุต","ุทููุงุช",
    "ุชูุฌูุฑ","ุงููุฌุงุฑ","ููุจูุฉ",
    "ุงุฎุชุทุงู","ุฎุทู","ูุฎุทูู",
    "ุณุฑูุฉ","ุณุทู","ููุจ",
    "ุชูุฏูุฏ","ุงุจุชุฒุงุฒ",

    # ===== ุงุนุชุฏุงุกุงุช ุฌูุณูุฉ =====
    "ุชุญุฑุด","ุงูุชุญุฑุด","ุชุญุฑุด ุฌูุณู",
    "ุงุนุชุฏุงุก ุฌูุณู","ุงุนุชุฏุงุกุงุช ุฌูุณูุฉ",
    "ุงุบุชุตุงุจ","ูุบุชุตุจ",
    "ูุชู ุนุฑุถ",
    "ุงูุชูุงู","ุงูุชูุงู ุฌุณุฏู",
    "ุงุณุชุบูุงู ุฌูุณู",
    "ุชุญุฑูุถ ุฌูุณู",

    # ===== ุฃุทูุงู ูููุตููุฑ (ุญุณุงุณุฉ ุฌุฏูุง) =====
    "ุทููุฉ","ุทูู","ูุงุตุฑ","ูุงุตุฑุฉ",
    "ุงูุงุนุชุฏุงุก ุนูู ุทูู",
    "ุงูุชุญุฑุด ุจุงูุฃุทูุงู",
    "ุงุณุชุบูุงู ุงูุฃุทูุงู",

    # ===== ุงูุชุญุงุฑ ูุฅูุฐุงุก ุงูููุณ =====
    "ุงูุชุญุงุฑ","ุงูุชุญุฑ","ููุชุญุฑ",
    "ุฅูุฐุงุก ุงูููุณ","ุฃุฐู ุงูููุณ",
    "ุดูู","ุดูู ููุณู",
    "ุชูุงูู ุณูู","ุฌุฑุนุฉ ุฒุงุฆุฏุฉ",

    # ===== ุฅุฑูุงุจ ูุชุทุฑู =====
    "ุฅุฑูุงุจ","ุฅุฑูุงุจู","ุชูุฌูุฑ ุฅุฑูุงุจู",
    "ุชูุธูู ุฅุฑูุงุจู","ุฏุงุนุด",
    "ุชูุฌูุฑุงุช","ุนูููุงุช ุฅุฑูุงุจูุฉ",

    # ===== ุฃููุงุธ ุฌูุณูุฉ ูุจุงุดุฑุฉ =====
    "ุฌูุณ","ุฌูุณูุฉ","ุนูุงูุฉ ุฌูุณูุฉ",
    "ุฅุจุงุญูุฉ","ููุงุฏ ุฅุจุงุญูุฉ",
    "ููุงุฑุณุฉ ุฌูุณูุฉ",

    # ===== ุชุญุฑูุถ ููุฑุงููุฉ =====
    "ุนูุตุฑูุฉ","ูุฑุงููุฉ","ุฎุทุงุจ ูุฑุงููุฉ",
    "ุชุญุฑูุถ","ุชุญุฑูุถ ุนูู ุงูุนูู",
    "ุณุจ","ุฅูุงูุฉ","ุชุดููุฑ",

    # ===== ูุฎุฏุฑุงุช =====
    "ูุฎุฏุฑุงุช","ูุฎุฏุฑ","ุญุดูุด","ุจุงูุฌู",
    "ููุฑููู","ูููุงููู","ุชุฑุงูุงุฏูู",
    "ุชุนุงุทู","ุชุฑููุฌ ูุฎุฏุฑุงุช",

    # ===== ูุถุงูุง ุญุณุงุณุฉ ูุงูููููุง =====
    "ูุณุงุฏ","ุฑุดูุฉ","ุงุฎุชูุงุณ",
    "ุชุฒููุฑ","ุชุฒููุฑ ุฃูุฑุงู",
    "ุบุณูู ุฃููุงู"
]

def split_sensitive_word(word):
    if word not in SENSITIVE_WORDS:
        return word
    symbol = random.choice(SEPARATORS)
    pos = len(word) // 2
    return word[:pos] + symbol + word[pos:]

def process_sensitive_text(text, limit_once=False):
    words = text.split()
    used = False
    out = []
    for w in words:
        if w in SENSITIVE_WORDS and (not used or not limit_once):
            out.append(split_sensitive_word(w))
            used = True
        else:
            out.append(w)
    return " ".join(out)

# ============================
# ุงูุฃูุงูู ูุงููุงุดุชุงุฌุงุช
# ============================
PLACES = [
    # ูุญุงูุธุงุช ูุตุฑ
    "ุงููุงูุฑุฉ","ุงูุฌูุฒุฉ","ุงูุฅุณููุฏุฑูุฉ","ุงูุฏููููุฉ","ุงูุดุฑููุฉ","ุงูููููุจูุฉ",
    "ููุฑ ุงูุดูุฎ","ุงูุบุฑุจูุฉ","ุงููููููุฉ","ุงูุจุญูุฑุฉ","ุฏููุงุท",
    "ุจูุฑุณุนูุฏ","ุงูุฅุณูุงุนูููุฉ","ุงูุณููุณ",
    "ุงููููู","ุจูู ุณููู","ุงููููุง","ุฃุณููุท","ุณููุงุฌ","ููุง","ุงูุฃูุตุฑ","ุฃุณูุงู",
    "ุงูุจุญุฑ ุงูุฃุญูุฑ","ุงููุงุฏู ุงูุฌุฏูุฏ","ูุทุฑูุญ","ุดูุงู ุณููุงุก","ุฌููุจ ุณููุงุก",

    # ูุญุงูุธุฉ ููุง
    "ูุฏููุฉ ููุง","ูุฑูุฒ ููุง",
    "ูุฌุน ุญูุงุฏู","ูุฑูุฒ ูุฌุน ุญูุงุฏู",
    "ุฏุดูุง","ูุฑูุฒ ุฏุดูุง",
    "ููุท","ูุฑูุฒ ููุท",
    "ููุต","ูุฑูุฒ ููุต",
    "ุฃุจู ุชุดุช","ูุฑูุฒ ุฃุจู ุชุดุช",
    "ูุฑุดูุท","ูุฑูุฒ ูุฑุดูุท",
    "ููุงุฏุฉ","ูุฑูุฒ ููุงุฏุฉ",
    "ุงูููู","ูุฑูุฒ ุงูููู"
]

GOV_ENTITIES = [
    "ุงูููุงุจุฉ ุงูุนุงูุฉ","ูุฒุงุฑุฉ ุงูุฏุงุฎููุฉ","ูุฒุงุฑุฉ ุงูุนุฏู",
    "ูุญููุฉ","ุงูุดุฑุทุฉ","ุงูุฃุฌูุฒุฉ ุงูุฃูููุฉ"
]

SECTIONS = {
    "ูุถุงุฆู": ["ูุญููุฉ","ุงูููุงุจุฉ","ุญูู","ูุถุช"],
    "ุฃููู": ["ุงููุจุถ","ุงูุฃูู","ุงูุดุฑุทุฉ","ุชูุชูุด"],
    "ุชุนูููู": ["ูุฏุฑุณ","ุทูุงุจ","ุชุนููู","ูุฏุฑุณุฉ"],
    "ุฑูุงุถู": ["ูุจุงุฑุงุฉ","ูุงุนุจ","ูุงุฏู","ุจุทููุฉ"]
}

def detect_section(text):
    for sec, keys in SECTIONS.items():
        for k in keys:
            if k in text:
                return sec
    return "ุฃุฎุจุงุฑ"

def normalize_hashtag(text):
    return text.replace(" ", "_")

def extract_safe_hashtags(text):
    tags = ["ููุง24"]

    for p in PLACES:
        if p in text:
            tags.append(normalize_hashtag(p))
            break

    for g in GOV_ENTITIES:
        if g in text:
            tags.append(normalize_hashtag(g))
            break

    tags.append(normalize_hashtag(detect_section(text)))

    return " ".join(f"#{t}" for t in tags)

# ============================
# ุชุฌููุฒ ุงููุต ุงูุนุฑุจู ููุตูุฑุฉ
# ============================
def prepare_arabic_lines(text, max_chars=40):
    words = text.split()
    lines, current = [], []

    for w in words:
        test = " ".join(current + [w])
        if len(test) <= max_chars:
            current.append(w)
        else:
            reshaped = arabic_reshaper.reshape(" ".join(current))
            lines.append(get_display(reshaped))
            current = [w]

    if current:
        reshaped = arabic_reshaper.reshape(" ".join(current))
        lines.append(get_display(reshaped))

    return lines

def fit_text_to_box(text):
    font_size = 52
    while font_size >= 24:
        lines = prepare_arabic_lines(text)
        total_height = len(lines) * LINE_HEIGHT
        if total_height <= MAX_HEIGHT:
            return lines, font_size
        font_size -= 2
    return lines, font_size

# ============================
# ุงูุชูููุฐ ุงูุฑุฆูุณู
# ============================
def main():
    feed = feedparser.parse(RSS_URL)

    posted = []
    if os.path.exists(POSTED_FILE):
        with open(POSTED_FILE, "r", encoding="utf-8") as f:
            posted = f.read().splitlines()

    for entry in feed.entries:
        raw_title = re.sub("<.*?>", "", entry.title).strip()
        raw_summary = re.sub("<.*?>", "", entry.summary).strip()

        h = hashlib.md5(raw_title.encode("utf-8")).hexdigest()
        if h in posted:
            continue

        title = process_sensitive_text(raw_title, limit_once=True)
        summary = process_sensitive_text(raw_summary)

        first_50 = " ".join(summary.split()[:50])

        caption = (
            f"{title}\n\n"
            f"{first_50}...\n\n"
            f"ุชุงุจุน ุงูุฎุจุฑ ูุงูู ููุง ๐\n{entry.link}\n\n"
            f"{extract_safe_hashtags(raw_title)}"
        )

        with Image(filename=BG_IMAGE) as canvas:

            try:
                match = re.search(r'<img[^>]+src="([^">]+)"', entry.summary)
                if match:
                    r = requests.get(match.group(1), timeout=10)
                    with Image(blob=r.content) as art:
                        art.transform(resize='855x460^')
                        art.extent(855, 460)
                        canvas.composite(art, 112, 185)
                else:
                    with Image(filename=LOGO_IMAGE) as logo:
                        logo.resize(855, 460)
                        canvas.composite(logo, 112, 185)
            except:
                pass

            lines, font_size = fit_text_to_box(title)
            total_h = len(lines) * LINE_HEIGHT
            start_y = TEXT_TOP + (MAX_HEIGHT - total_h) // 2

            with Drawing() as draw:
                draw.font = FONT_FILE
                draw.font_size = font_size
                draw.fill_color = Color("black")
                draw.text_alignment = "center"

                y = start_y
                for line in lines:
                    draw.text(CENTER_X, y, line)
                    y += LINE_HEIGHT

                draw(canvas)

            canvas.save(filename="final.png")

        with open("final.png", "rb") as img:
            res = requests.post(
                FB_URL,
                data={"access_token": PAGE_ACCESS_TOKEN, "caption": caption},
                files={"source": img}
            )

        if res.status_code == 200:
            with open(POSTED_FILE, "a", encoding="utf-8") as f:
                f.write(h + "\n")

            subprocess.run(["git", "config", "--global", "user.name", "Bot"])
            subprocess.run(["git", "config", "--global", "user.email", "bot@github.com"])
            subprocess.run(["git", "add", POSTED_FILE])
            subprocess.run(["git", "commit", "-m", "update posted articles"], check=False)
            subprocess.run(["git", "push"], check=False)

            print("โ ุชู ุงููุดุฑ ุจูุฌุงุญ")
            break

if __name__ == "__main__":
    main()
