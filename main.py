# -*- coding: utf-8 -*-
import feedparser
import requests
import hashlib
import os
import re
import random
import subprocess

from wand.image import Image
from wand.drawing import Drawing
from wand.color import Color

import arabic_reshaper
from bidi.algorithm import get_display

# ============================
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
# ============================
RSS_URL = "https://qenanews-24.blogspot.com/feeds/posts/default?alt=rss"

FONT_FILE = "29ltbukrabolditalic.otf"
BG_PATH = "BG.png"
LOGO_PATH = "logo1.png"

CENTER_X = 540
START_Y = 780
LINE_HEIGHT = 75

PAGE_ID = os.getenv("PAGE_ID", "").strip()
PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN", "").strip()
FB_URL = f"https://graph.facebook.com/v19.0/{PAGE_ID}/photos"

POSTED_FILE = "posted_articles.txt"

# ============================
# ÙƒÙ„Ù…Ø§Øª Ø­Ø³Ø§Ø³Ø© + ÙÙˆØ§ØµÙ„
# ============================
SEPARATORS = ["$", "&", "%", "*", "~", "+", "|", "â€¢", "=", "^", ":", "!", "Â·", "âƒ"]

SENSITIVE_WORDS = [
    "ØªØ­Ø±Ø´","ØªØ­Ø±Ø´Ø§Øª","Ø§ØºØªØµØ§Ø¨","Ø§Ø¹ØªØ¯Ø§Ø¡","Ø§Ø¹ØªØ¯Ø§Ø¡Ø§Øª","Ø¬Ù†Ø³ÙŠ","Ø¬Ù†Ø³ÙŠØ©",
    "Ù‚ØªÙ„","Ø¬Ø±ÙŠÙ…Ø©","Ø°Ø¨Ø­","Ø¬Ø«Ø©","Ø¯Ù…","Ø¯Ù…Ø§Ø¡","Ø·Ø¹Ù†","ØªÙØ¬ÙŠØ±","Ø§Ù†ØªØ­Ø§Ø±",
    "Ø¥Ø±Ù‡Ø§Ø¨","Ø¥Ø±Ù‡Ø§Ø¨ÙŠ","ÙƒØ±Ø§Ù‡ÙŠØ©","Ø¹Ù†ØµØ±ÙŠØ©",
    "Ø§Ø´ØªØ±Ùƒ","Ø§Ø¶ØºØ·","Ø§Ù„Ø¢Ù†","Ù…Ø¬Ø§Ù†Ø§","Ø¹Ø±Ø¶","Ø§Ø±Ø¨Ø­"
]

STOP_WORDS = [
    "Ù‡Ø°Ø§","Ù‡Ø°Ù‡","Ø°Ù„Ùƒ","Ø§Ù„ØªÙŠ","Ø§Ù„Ø°ÙŠ","Ø¹Ù„Ù‰","ÙÙŠ","Ù…Ù†","Ø¥Ù„Ù‰","Ø¹Ù†",
    "Ù…Ø¹","ÙƒØ§Ù†","ÙƒÙ…Ø§","Ø¨Ø¹Ø¯","Ù‚Ø¨Ù„","Ø¨ÙŠÙ†","Ø£Ù…Ø§Ù…","Ø®Ù„Ø§Ù„"
]

# ============================
# ÙƒØ³Ø± Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
# ============================
def split_sensitive_word(word):
    if word not in SENSITIVE_WORDS:
        return word

    def m1(w):
        pos = len(w) // 2
        return w[:pos] + random.choice(SEPARATORS) + w[pos:]

    def m2(w):
        repl = {
            "Ø§": random.choice(["Ø£","Ø¥","Ø¢"]),
            "ÙŠ": "Ù‰",
            "Ù‡": "Ø©",
            "Ùˆ": "Ø¤"
        }
        for k, v in repl.items():
            if k in w:
                return w.replace(k, v, 1)
        return m1(w)

    def m3(w):
        pos = len(w) // 2
        return w[:pos] + " " + w[pos:]

    def m4(w):
        pos = 1
        return w[:pos] + random.choice(["Â·","âƒ"]) + w[pos:]

    return random.choice([m1, m2, m3, m4])(word)

def process_sensitive_text(text):
    return " ".join(split_sensitive_word(w) for w in text.split())

# ============================
# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ RTL
# ============================
def process_arabic_lines(text, max_chars=35):
    words = text.split()
    lines, current = [], []

    for w in words:
        test = " ".join(current + [w])
        if len(test) <= max_chars:
            current.append(w)
        else:
            reshaped = arabic_reshaper.reshape(" ".join(current))
            lines.append(get_display(reshaped))
            current = [w]

    if current:
        reshaped = arabic_reshaper.reshape(" ".join(current))
        lines.append(get_display(reshaped))

    return lines

# ============================
# Ø£ÙˆÙ„ 50 ÙƒÙ„Ù…Ø©
# ============================
def extract_summary(text, limit=50):
    words = text.split()
    return process_sensitive_text(" ".join(words[:limit]))

# ============================
# Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª Ø¢Ù…Ù†Ø© + Ø«Ø§Ø¨Øª
# ============================
def extract_hashtags(text, max_tags=4):
    words = re.findall(r"[Ø§Ø£Ø¥Ø¢Ø¡-ÙŠ]{4,}", text)
    clean = []

    for w in words:
        w = re.sub(r"[^\u0600-\u06FF]", "", w)
        if w and w not in STOP_WORDS and w not in SENSITIVE_WORDS:
            clean.append(w)

    unique = list(dict.fromkeys(clean))
    dynamic = unique[:max_tags]

    tags = ["Ù‚Ù†Ø§24"] + dynamic
    tags = [process_sensitive_text(t) for t in tags]

    return " ".join(f"#{t}" for t in tags)

# ============================
# MAIN
# ============================
def main():
    if not PAGE_ID or not PAGE_ACCESS_TOKEN:
        print("âŒ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠØ³Ø¨ÙˆÙƒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        return

    feed = feedparser.parse(RSS_URL)

    posted = []
    if os.path.exists(POSTED_FILE):
        with open(POSTED_FILE, "r", encoding="utf-8") as f:
            posted = f.read().splitlines()

    for entry in feed.entries:
        raw_title = re.sub("<.*?>", "", entry.title).strip()
        raw_text = re.sub("<.*?>", "", entry.summary).strip()

        h = hashlib.md5((raw_title + raw_text).encode("utf-8")).hexdigest()
        if h in posted:
            continue

        print("ğŸ”„ Ø®Ø¨Ø± Ø¬Ø¯ÙŠØ¯:", raw_title)

        # ÙƒØ³Ø± Ø§Ù„Ù†ØµÙˆØµ
        safe_title = process_sensitive_text(raw_title)
        safe_summary = extract_summary(raw_text)
        hashtags = extract_hashtags(raw_text)

        # ===== Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© =====
        with Image(filename=BG_PATH) as canvas:

            # ØµÙˆØ±Ø© Ø§Ù„Ø®Ø¨Ø±
            try:
                match = re.search(r'<img[^>]+src="([^">]+)"', entry.summary)
                if match:
                    r = requests.get(match.group(1), timeout=10)
                    with Image(blob=r.content) as img:
                        img.transform(resize='855x460^')
                        img.extent(width=855, height=460)
                        canvas.composite(img, left=112, top=185)
                else:
                    with Image(filename=LOGO_PATH) as logo:
                        logo.resize(855, 460)
                        canvas.composite(logo, left=112, top=185)
            except:
                pass

            # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© (Ù…ÙƒØ³ÙˆØ± + RTL)
            image_title = process_sensitive_text(raw_title)
            lines = process_arabic_lines(image_title)

            with Drawing() as draw:
                draw.font = FONT_FILE
                draw.font_size = 50
                draw.fill_color = Color("black")
                draw.text_alignment = "center"

                y = START_Y
                for line in lines:
                    draw.text(CENTER_X, y, line)
                    y += LINE_HEIGHT

                draw(canvas)

            canvas.save(filename="final.png")

        # ===== Ø§Ù„ÙƒØ§Ø¨Ø´Ù† =====
        raw_caption = (
            f"{safe_title}\n\n"
            f"{safe_summary}...\n\n"
            f"ØªØ§Ø¨Ø¹ Ø§Ù„Ø®Ø¨Ø± ÙƒØ§Ù…Ù„ Ù‡Ù†Ø§ ğŸ‘‡\n"
            f"{entry.link}\n\n"
            f"{hashtags}"
        )

        caption = process_sensitive_text(raw_caption)

        with open("final.png", "rb") as img:
            res = requests.post(
                FB_URL,
                data={"access_token": PAGE_ACCESS_TOKEN, "caption": caption},
                files={"source": img}
            )

        if res.status_code == 200:
            print("âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø±")
            with open(POSTED_FILE, "a", encoding="utf-8") as f:
                f.write(h + "\n")

            subprocess.run(["git", "config", "--global", "user.name", "Bot"])
            subprocess.run(["git", "config", "--global", "user.email", "bot@github.com"])
            subprocess.run(["git", "add", POSTED_FILE])
            subprocess.run(["git", "commit", "-m", "Update posted articles"], check=False)
            subprocess.run(["git", "push"], check=False)
            break

# ============================
if __name__ == "__main__":
    main()
